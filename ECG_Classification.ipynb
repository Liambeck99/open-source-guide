{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OjiZbCAZHTu5HU6cpPJ3WtPJo4Ry9evH",
      "authorship_tag": "ABX9TyPY+TiQ2O26DlYSVClY8ghP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liambeck99/open-source-guide/blob/18f-pages/ECG_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPiuV5vQDkqg"
      },
      "source": [
        "# ECG Classification\r\n",
        "\r\n",
        "## Project Goal\r\n",
        "The goal of this project is to create a deep neural network able to classify ECG signals and cardiac arrhythmia with a high degree of accuracy. Alongside this goal is the aim to explore the implications of introducing simulated data into the training sets in hopes of improving the overall accuracy of the model.\r\n",
        "\r\n",
        "The model created and used for this project is based off of the model preseneted in the Yildrim20 paper :\r\n",
        "https://www.sciencedirect.com/science/article/abs/pii/S016926072031573X\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6aL6ZR7J_pb"
      },
      "source": [
        "#### Firstly import all of the neccesary librarys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5DqKG0oKKmj"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "import scipy.io\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization, LeakyReLU, Dropout, LSTM, Flatten, Dense \r\n",
        "from keras.utils import to_categorical\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcBw6hRZKfef"
      },
      "source": [
        "#### Import the datafiles for training and testing\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq3fxc5lmEx8",
        "outputId": "00a73890-a436-44fd-8694-ee2ab5b2c466"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5uitvmJKmgM"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/ECG/ammendedData/ammendedData.csv\").values\r\n",
        "labels = pd.read_csv(\"/content/drive/My Drive/ECG/ammendedData/ammendedLabels.csv\").values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2bu3pFJqhTZ"
      },
      "source": [
        "X_train = np.array(data[0:250])\r\n",
        "X_train = X_train[..., None]\r\n",
        "Y_train = np.array(labels[0:250])\r\n",
        "\r\n",
        "X_test = np.array(data[251:301])\r\n",
        "X_test = X_test[..., None]\r\n",
        "Y_test = np.array(labels[251:301])\r\n",
        "\r\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\r\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRWFuQ_O3hcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067ffd4e-09e7-4ee4-8f85-a32dd05f7182"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "encoder = LabelBinarizer()\r\n",
        "Y_train = encoder.fit_transform(Y_train)\r\n",
        "Y_test = encoder.fit_transform(Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 1]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFw6SZd1Lc74"
      },
      "source": [
        "#### Initialise variables needed for the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwVUmTKsLl_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1206763-8fe3-46f2-9350-c5a30a7089fb"
      },
      "source": [
        "nb_epoch = 1 # Make larger later\r\n",
        "\r\n",
        "batch_size = 250\r\n",
        "\r\n",
        "# more ...\r\n",
        "\r\n",
        "print(X_train.shape)\r\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 5000, 1)\n",
            "(30, 5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqb1iCKhNn_V"
      },
      "source": [
        "#### Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY5NKmzRNsG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce7439a-17b0-48fa-b17a-22ac1bdb7804"
      },
      "source": [
        "# Initialise model\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# 'Input' layer chunk\r\n",
        "model.add( Conv1D( filters=64, kernel_size=21, strides=11, input_shape=[5000, 1] ) )\r\n",
        "model.add( MaxPooling1D( pool_size=2 ) )\r\n",
        "model.add( BatchNormalization() )\r\n",
        "model.add( LeakyReLU( alpha=0.1 ) )\r\n",
        "model.add( Dropout( rate=0.3 ) )\r\n",
        "\r\n",
        "# Hidden layers\r\n",
        "model.add( Conv1D( filters=64, kernel_size=7, strides=1, input_shape=[64, 226] ) )\r\n",
        "model.add( MaxPooling1D( pool_size=2 ) )\r\n",
        "model.add( BatchNormalization() )\r\n",
        "\r\n",
        "model.add( Conv1D( filters=128, kernel_size=5, strides=1, input_shape=[64, 110] ) )\r\n",
        "model.add( MaxPooling1D( pool_size=2 ) )\r\n",
        "\r\n",
        "model.add( Conv1D( filters=256, kernel_size=13, strides=1, input_shape=[128, 53] ) )\r\n",
        "model.add( Conv1D( filters=512, kernel_size=7, strides=1, input_shape=[256, 41] ) )\r\n",
        "model.add( Dropout( rate=0.3 ) )\r\n",
        "\r\n",
        "model.add( Conv1D( filters=256, kernel_size=9, strides=1, input_shape=[512, 35] ) )\r\n",
        "model.add( MaxPooling1D( pool_size=2 ) )\r\n",
        "\r\n",
        "# 'Output' layer chunk\r\n",
        "model.add( LSTM( units=128, return_sequences=True) )\r\n",
        "model.add( Flatten() )\r\n",
        "model.add( Dense( units=64, activation='relu' ) )\r\n",
        "model.add( Dense( units=4, activation='softmax' ) )\r\n",
        "\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_48 (Conv1D)           (None, 453, 64)           1408      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_32 (MaxPooling (None, 226, 64)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 226, 64)           256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 226, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 226, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_49 (Conv1D)           (None, 220, 64)           28736     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_33 (MaxPooling (None, 110, 64)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 110, 64)           256       \n",
            "_________________________________________________________________\n",
            "conv1d_50 (Conv1D)           (None, 106, 128)          41088     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_34 (MaxPooling (None, 53, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_51 (Conv1D)           (None, 41, 256)           426240    \n",
            "_________________________________________________________________\n",
            "conv1d_52 (Conv1D)           (None, 35, 512)           918016    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 35, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_53 (Conv1D)           (None, 27, 256)           1179904   \n",
            "_________________________________________________________________\n",
            "max_pooling1d_35 (MaxPooling (None, 13, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 13, 128)           197120    \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1664)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                106560    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 2,899,844\n",
            "Trainable params: 2,899,588\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipNMXtOC58ai"
      },
      "source": [
        "#### Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ErW5GMm6OVp"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.002)\r\n",
        "model.compile(\r\n",
        "    loss = \"categorical_crossentropy\",\r\n",
        "    optimizer=opt,\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8surBBXD9-Yh"
      },
      "source": [
        "#### Fit model on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNu5zgxX-Crq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31a0a91-eff0-4f57-c447-88571facd618"
      },
      "source": [
        "model.fit(\r\n",
        "    X_train, Y_train,\r\n",
        "    validation_data=(X_test, Y_test),\r\n",
        "    epochs=30,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 7s 653ms/step - loss: 0.9903 - accuracy: 0.5880 - val_loss: 0.9740 - val_accuracy: 0.6000\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 5s 571ms/step - loss: 0.9947 - accuracy: 0.5880 - val_loss: 0.9659 - val_accuracy: 0.6000\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 4s 561ms/step - loss: 0.9767 - accuracy: 0.5880 - val_loss: 0.9628 - val_accuracy: 0.6000\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 4s 557ms/step - loss: 0.9703 - accuracy: 0.5880 - val_loss: 0.9607 - val_accuracy: 0.6000\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 4s 559ms/step - loss: 0.9775 - accuracy: 0.5880 - val_loss: 0.9734 - val_accuracy: 0.6000\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 4s 560ms/step - loss: 0.9833 - accuracy: 0.5800 - val_loss: 0.9784 - val_accuracy: 0.6000\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 4s 557ms/step - loss: 0.9753 - accuracy: 0.5880 - val_loss: 0.9887 - val_accuracy: 0.6000\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 5s 564ms/step - loss: 0.9849 - accuracy: 0.5880 - val_loss: 0.9906 - val_accuracy: 0.6000\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 4s 560ms/step - loss: 0.9824 - accuracy: 0.5880 - val_loss: 0.9886 - val_accuracy: 0.6000\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 4s 560ms/step - loss: 0.9781 - accuracy: 0.5840 - val_loss: 0.9961 - val_accuracy: 0.6000\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 4s 558ms/step - loss: 0.9627 - accuracy: 0.5920 - val_loss: 0.9937 - val_accuracy: 0.6000\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 4s 562ms/step - loss: 0.9805 - accuracy: 0.5880 - val_loss: 1.0045 - val_accuracy: 0.6000\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 4s 558ms/step - loss: 0.9745 - accuracy: 0.5880 - val_loss: 1.0180 - val_accuracy: 0.6000\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 4s 560ms/step - loss: 0.9742 - accuracy: 0.5920 - val_loss: 1.0172 - val_accuracy: 0.6000\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 4s 560ms/step - loss: 0.9674 - accuracy: 0.5880 - val_loss: 1.0338 - val_accuracy: 0.6000\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 4s 562ms/step - loss: 0.9773 - accuracy: 0.5880 - val_loss: 1.0490 - val_accuracy: 0.6000\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 5s 569ms/step - loss: 0.9817 - accuracy: 0.5920 - val_loss: 1.0031 - val_accuracy: 0.6000\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 5s 567ms/step - loss: 0.9707 - accuracy: 0.5840 - val_loss: 1.0115 - val_accuracy: 0.6000\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 5s 564ms/step - loss: 0.9731 - accuracy: 0.5880 - val_loss: 1.0200 - val_accuracy: 0.6000\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 5s 564ms/step - loss: 0.9796 - accuracy: 0.5840 - val_loss: 1.0119 - val_accuracy: 0.6000\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 5s 574ms/step - loss: 0.9945 - accuracy: 0.5840 - val_loss: 1.0074 - val_accuracy: 0.6000\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 5s 568ms/step - loss: 0.9645 - accuracy: 0.5880 - val_loss: 1.0017 - val_accuracy: 0.6000\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 5s 571ms/step - loss: 0.9569 - accuracy: 0.5880 - val_loss: 0.9920 - val_accuracy: 0.6000\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 5s 566ms/step - loss: 0.9733 - accuracy: 0.5880 - val_loss: 1.0236 - val_accuracy: 0.6000\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 5s 566ms/step - loss: 0.9705 - accuracy: 0.5920 - val_loss: 1.0049 - val_accuracy: 0.6000\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 5s 569ms/step - loss: 0.9655 - accuracy: 0.5920 - val_loss: 0.9674 - val_accuracy: 0.6000\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 4s 561ms/step - loss: 0.9992 - accuracy: 0.5880 - val_loss: 0.9524 - val_accuracy: 0.6000\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 5s 568ms/step - loss: 0.9950 - accuracy: 0.5880 - val_loss: 0.9860 - val_accuracy: 0.6000\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 5s 564ms/step - loss: 1.0073 - accuracy: 0.5880 - val_loss: 1.0206 - val_accuracy: 0.6000\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 5s 568ms/step - loss: 1.0039 - accuracy: 0.5880 - val_loss: 1.0325 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7effc6573a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTM3mtfn-Ppq"
      },
      "source": [
        "#### Evaluate the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ_FvWry-TUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce72aaa3-2bfa-4046-b1e9-28ca52009888"
      },
      "source": [
        "score = model.evaluate(\r\n",
        "    X_test,\r\n",
        "    Y_test\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 4s 114ms/step - loss: 0.9807 - accuracy: 0.6046\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}